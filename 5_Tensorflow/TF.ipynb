{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow architecture\n",
    "\n",
    "TensorFlow is a Python Library that allows users to express arbitrary computation as a graph of data flows. Nodes in this graph represent mathematical operations (ops), whereas edges represent data that is communicated from one node to\n",
    "another. \n",
    "\n",
    "Computation is defined as Directed Acyclic Graph (DAG, similar to Spark!):\n",
    "  1. Graph is defined in a high-level language like C++, Python, go\n",
    "  1. Graph is compiled and optimized\n",
    "  1. Data (tensors) flow through graph\n",
    "\n",
    "Data in TensorFlow are represented as tensors, which are multidimensional arrays. Although this framework for thinking about computation is valuable in many different fields, TensorFlow is primarily used for deep learning in practice and\n",
    "research.\n",
    "\n",
    "  1. Core written in C++\n",
    "  1. Different front-ends\n",
    "      1. Python and C++ as of today\n",
    "      1. Community is expected to add more \n",
    "\n",
    "\n",
    "<img src=\"../graphics/tf_architecture.png\">\n",
    "\n",
    "\n",
    "\n",
    "## Constants\n",
    "\n",
    "Constants are the operations that do not need any input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 12.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# Create a Constant op that produces a 1x2 matrix.  The op is\n",
    "# added as a node to the default graph.\n",
    "#\n",
    "# The value returned by the constructor represents the output\n",
    "# of the Constant op.\n",
    "matrix1 = tf.constant([[3., 3.]])\n",
    "\n",
    "# Create another Constant that produces a 2x1 matrix.\n",
    "matrix2 = tf.constant([[2.],[2.]])\n",
    "\n",
    "# Create a Matmul op that takes 'matrix1' and 'matrix2' as inputs.\n",
    "# The returned value, 'product', represents the result of the matrix\n",
    "# multiplication.\n",
    "product = tf.matmul(matrix1, matrix2)\n",
    "print product.eval()\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables\n",
    "\n",
    "TensorFlow variables are in-memory buffers that contain tensors, they are present across multiple executions of a graph. A TensorFlow variables have the following three properties:\n",
    "  1. Variables must be explicitly initialized before a graph is used for the first time\n",
    "  1. We can use gradient methods to modify variables after each iteration as we search for a modelâ€™s optimal parameter settings\n",
    "  1. We can save the values stored in variables to disk and restore them for later use.\n",
    "\n",
    "\n",
    "Creating a variable is simple, following creates a random variable with a given range and standard deviation:\n",
    "\n",
    "```python\n",
    "weights = tf.Variable(tf.random_normal([300, 200], stddev=0.5),\n",
    "name=\"weights\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "# Create a Variable, that will be initialized to the scalar value 0.\n",
    "state = tf.Variable(0, name=\"counter\")\n",
    "\n",
    "# Create an Op to add one to `state`.\n",
    "one = tf.constant(1)\n",
    "new_value = tf.add(state, one)\n",
    "update = tf.assign(state, new_value)\n",
    "\n",
    "# Variables must be initialized by running an `init` Op after having\n",
    "# launched the graph.  We first have to add the `init` Op to the graph.\n",
    "init_op = tf.initialize_all_variables()\n",
    "\n",
    "# Launch the graph and run the ops.\n",
    "# Run the 'init' op\n",
    "sess.run(init_op)\n",
    "# Print the initial value of 'state'\n",
    "print(sess.run(state))\n",
    "# Run the op that updates 'state' and print 'state'.\n",
    "for _ in range(3):\n",
    "    sess.run(update)\n",
    "    print(sess.run(state))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to NumPy, one can use a set of predefined functions to create some common tensors:\n",
    "\n",
    "```python\n",
    "#tensor of zeros of a given shape and type float32\n",
    "tf.zeros(shape, dtype=tf.float32, name=None)\n",
    "\n",
    "#tensor of all ones with a given shape and element type float32\n",
    "tf.ones(shape, dtype=tf.float32, name=None)\n",
    "\n",
    "#random normal tensor of a given shape, mean and standard deciation\n",
    "tf.random_normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32,seed=None, name=None)\n",
    "\n",
    "#same, random uniform\n",
    "tf.random_uniform(shape, minval=0, maxval=None, dtype=tf.float32,seed=None, name=None)\n",
    "```\n",
    "\n",
    "## TF operations\n",
    "\n",
    "On a high-level, TensorFlow operations represent abstract transformations\n",
    "that are applied to tensors in the computation graph. Operations may have\n",
    "attributes that may be supplied before or during runtime. \n",
    "\n",
    "An operation consists of one or more kernels, which represent device-specific implementations.\n",
    "For example, an operation may have separate CPU and GPU kernels\n",
    "because it can be more efficiently expressed on a GPU. \n",
    "\n",
    "To provide an overview of the types of operations available, we include a table from\n",
    "the original TensorFlow white paper detailing the various categories of operations in\n",
    "TensorFlow.\n",
    "\n",
    "Following table summarizes the mathematical ops available in Tensorflow\n",
    "\n",
    "<pre>\n",
    "|-------------------------------------------------------------------------------------------------\n",
    "| Type                                | Examples                                                 |\n",
    "|------------------------------------------------------------------------------------------------|\n",
    "|Element-wise mathematical operations | Add, Sub, Mul, Div, Exp, Log, Greater, Less, Equal, ...  |\n",
    "|Array operations                     |Concat, Slice, Split, Constant, Rank, Shape, Shuffle, ... |\n",
    "|Matrix operations                    |MatMul, MatrixInverse, MatrixDeterminant, ...             | \n",
    "|Stateful operations                  |Variable, Assign, AssignAdd, ...                          |\n",
    "|Neural network building blocks       |SoftMax, Sigmoid, ReLU, Convolution2D, MaxPool, ...       |   \n",
    "|Checkpointing operations             |Save, Restore                                             |\n",
    "|Queue and synchronization operations |Enqueue, Dequeue, MutexAcquire, MutexRelease, ...         |\n",
    "|Control flow operations              |Merge, Switch, Enter, Leave, NextIteration                |\n",
    "|-------------------------------------------------------------------------------------------------\n",
    "</pre>\n",
    "\n",
    "## TF placeholders\n",
    "\n",
    "A variable is meant to be initialized only once. If we need to feed some external input to our calculation, we would need to use something that we could populate every iteration.\n",
    "\n",
    "TensorFlow solves this problem using a construct called a placeholder. A placeholder\n",
    "is instantiated as follows and can be used in operations just like ordinary TensorFlow\n",
    "variables and tensors.\n",
    "\n",
    "You supply feed data as an argument to a run() call. The feed is only used for the run call to which it is passed. The most common use case involves designating specific operations to be \"feed\" operations by using tf.placeholder() to create them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 14.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "input1 = tf.placeholder(tf.float32)\n",
    "input2 = tf.placeholder(tf.float32)\n",
    "output = tf.mul(input1, input2)\n",
    "\n",
    "print(sess.run([output], feed_dict={input1:[7.], input2:[2.]}))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A placeholder() operation generates an error if you do not supply a feed for it. See the MNIST fully-connected feed tutorial (source code) for a larger-scale example of feeds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session\n",
    "\n",
    "A TensorFlow program interacts with a computation graph using a session. The TensorFlow\n",
    "session is responsible for building the initial graph, can be used to initialize\n",
    "all variables appropriately, and to run the computational graph. In Jupyter notebook we use an InteractiveSession and eval function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression model\n",
    "\n",
    "Let us add some complexity to the problems we are solving and move on to the linear regression model example.\n",
    "\n",
    "Consider equation: `y = 0.1 * x + 0.3 + noise`\n",
    "Which we are going to try to model with the following: `y = W * x + b`\n",
    "\n",
    "Our goal is to figure out the value of `W` and `b`, given enough `(x, y)` value samples.\n",
    "\n",
    "This is how we are going to solve it:\n",
    "\n",
    "\n",
    "   1. Import libraries (cell 1.1)\n",
    "   1. Create input data (cell 1.2)\n",
    "   1. Build inference graph (cell 1.3)\n",
    "      1. Create Variables to hold weights and biases.\n",
    "      1. Create Operations that produce logistic outputs.\n",
    "   1. Build training graph (cell 1.4)\n",
    "      1. Loss\n",
    "      1. Optimizer\n",
    "      1. Train_op: Operation that minimizes Loss\n",
    "   1. Create session and run initialization (cell 1.5)\n",
    "   1. Perform training (cell 1.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1.1 Import tensorflow and other libraries.\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1.2 Create input data using NumPy. y = x * 0.1 + 0.3 + noise\n",
    "x_data = np.random.rand(100).astype(np.float32)\n",
    "noise = np.random.normal(scale=0.01, size=len(x_data))\n",
    "y_data = x_data * 0.1 + 0.3 + noise\n",
    "\n",
    "# Uncomment the following line to plot our input data.\n",
    "#pylab.plot(x_data, y_data, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1.3 Buld inference graph.\n",
    "# Create Variables W and b that compute y_data = W * x_data + b\n",
    "W = tf.Variable(tf.random_uniform([1], 0.0, 1.0))\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "y = W * x_data + b\n",
    "\n",
    "# Uncomment the following lines to see W and b are.\n",
    "# print(W)\n",
    "# print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1.4 Build training graph.\n",
    "loss = tf.reduce_mean(tf.square(y - y_data))  # Create an operation that calculates loss.\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5)  # Create an optimizer.\n",
    "train = optimizer.minimize(loss)  # Create an operation that minimizes loss.\n",
    "init = tf.initialize_all_variables()  # Create an operation initializes all the variables.\n",
    "\n",
    "# Uncomment the following 3 lines to see what 'loss', 'optimizer' and 'train' are.\n",
    "# print(\"loss:\", loss)\n",
    "# print(\"optimizer:\", optimizer)\n",
    "# print(\"train:\", train)\n",
    "# print(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1.5 Uncomment the following line to see what we have built.\n",
    "#print(tf.get_default_graph().as_graph_def())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1.6 Create a session and launch the graph.\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)\n",
    "y_initial_values = sess.run(y)  # Save initial values for plotting later.\n",
    "\n",
    "# Uncomment the following line to see the initial W and b values.\n",
    "# print(sess.run([W, b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 0.1024311], dtype=float32), array([ 0.29756743], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# 1.7 Perform training.\n",
    "for step in range(201):\n",
    "    sess.run(train)\n",
    "    # Uncomment the following two lines to watch training happen real time.\n",
    "    # if step % 20 == 0:\n",
    "    #    print(step, sess.run([W, b]))\n",
    "\n",
    "print(sess.run([W, b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1.8 Uncomment the following lines to compare.\n",
    "# pylab.plot(x_data, y_data, '.', label=\"target_values\")\n",
    "# pylab.plot(x_data, y_initial_values, \".\", label=\"initial_values\")\n",
    "# pylab.plot(x_data, sess.run(y), \".\", label=\"trained_values\")\n",
    "# pylab.legend()\n",
    "# pylab.ylim(0, 1.0)\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<p>Continue on to the MNIST exercise: [MNIST.ipynb](MNIST.ipynb).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
