{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data parallelism with Python\n",
    "\n",
    "https://docs.python.org/2/library/multiprocessing.html\n",
    "\n",
    "We have seen how one can use OpenMP and shared memory programming to parallelized python code (well, Cython).\n",
    "\n",
    "## Multiprocessing library\n",
    "\n",
    "**multiprocessing** allows to utilize multiple processors on a given machine. It introduces a Pool object which offers a means of parallelizing the execution of a function across multiple input values, distributing the input data across processes (**data parallelism**). \n",
    "\n",
    "### Pool class\n",
    "\n",
    "This basic example of data parallelism using the Pool class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 9, 16]\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "def f(x):\n",
    "    return x*x\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #specify number of child processes to spawn, use <= number of processes available\n",
    "    nprocs = mp.cpu_count()\n",
    "    p = mp.Pool(nprocs)\n",
    "    print(p.map(f, [1, 2, 3, 4]))\n",
    "    print(mp.cpu_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process and Queue classes\n",
    "\n",
    "In `multiprocessing`, individual processes are spawned by creating a `Process` object or sub-classing it.\n",
    "In the following example we are going to use the `multiprocessing.Queue` class which returns a process shared queue implemented using a pipe and a few locks. When a process first puts an item on the queue a feeder thread is started which transfers objects from a buffer into the pipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULT: Process idx=0 is called 'Worker-41'\n",
      "RESULT: Process idx=1 is called 'Worker-42'\n",
      "RESULT: Process idx=2 is called 'Worker-43'\n",
      "RESULT: Process idx=3 is called 'Worker-44'\n",
      "RESULT: Process idx=4 is called 'Worker-45'\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process, Queue\n",
    "\n",
    "class Worker(Process):\n",
    "\n",
    "    def __init__(self, queue, idx, data):\n",
    "        super(Worker, self).__init__()\n",
    "        self.queue = queue\n",
    "        self.idx = idx\n",
    "        self.data = data\n",
    "\n",
    "    def square(self):\n",
    "        self.data = map(lambda x: x*x, self.data)\n",
    "        return \"Process idx=%s is called '%s'\" % (self.idx, self.name)\n",
    "\n",
    "    def run(self):\n",
    "        self.queue.put(self.square())\n",
    "\n",
    "## Create a list to hold running Worker objects\n",
    "worker_processes = list()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    data = [1,2,3,4]  \n",
    "    q = Queue()\n",
    "    for i in range(5):\n",
    "        p=Worker(queue=q, idx=i,data=data)\n",
    "        worker_processes.append(p)\n",
    "        p.start()\n",
    "    for proc in worker_processes:\n",
    "        proc.join()\n",
    "        print \"RESULT: %s\" % q.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joblib library\n",
    "\n",
    "https://pythonhosted.org/joblib/\n",
    "\n",
    "Joblib is a set of tools to provide data parallelism and pipelining in Python. \n",
    "\n",
    "joblib offers:\n",
    "   1. disk-caching of the output values and lazy re-evaluation\n",
    "   1. easy simple parallel computing\n",
    "\n",
    "Let us go back to our dot poroduct example, and we will assume that we need to perfrom this to a list of vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 6.91 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.3338099651261235e+17,\n",
       " 3.3338099651261235e+17,\n",
       " 3.3338099651261235e+17,\n",
       " 3.3338099651261235e+17,\n",
       " 3.3338099651261235e+17,\n",
       " 3.3338099651261235e+17,\n",
       " 3.3338099651261235e+17,\n",
       " 3.3338099651261235e+17,\n",
       " 3.3338099651261235e+17,\n",
       " 3.3338099651261235e+17]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from cython_dot2 import dot_product\n",
    "\n",
    "Nvectors = 10\n",
    "results = list()\n",
    "\n",
    "for round in range(Nvectors):\n",
    "    vec1 = np.arange(1000000,dtype=float)\n",
    "    vec2 = np.arange(1000000,dtype=float)\n",
    "    results.append(dot_product(vec1,vec2))\n",
    "\n",
    "%time results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Running on ', 2, ' CPU cores')\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 6.91 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.4287628162912635e+23,\n",
       " 2.4287628162912635e+23,\n",
       " 2.4287628162912635e+23,\n",
       " 2.4287628162912635e+23,\n",
       " 2.4287628162912635e+23,\n",
       " 2.4287628162912635e+23,\n",
       " 2.4287628162912635e+23,\n",
       " 2.4287628162912635e+23,\n",
       " 2.4287628162912635e+23,\n",
       " 2.4287628162912635e+23]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import Parallel, delayed  \n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "from cython_dot2 import dot_product\n",
    "\n",
    "num_cores = 2 #multiprocessing.cpu_count()-1\n",
    "print(\"Running on \", num_cores, \" CPU cores\")\n",
    "\n",
    "Nvectors = 10\n",
    "results = list()\n",
    "\n",
    "def getProduct():\n",
    "    vec1 = np.arange(100000000,dtype=float)\n",
    "    vec2 = np.arange(100000000,dtype=float)\n",
    "    return dot_product(vec1,vec2)\n",
    "\n",
    "results = Parallel(n_jobs=num_cores)(delayed(getProduct)() for i in range(Nvectors))  \n",
    "\n",
    "%time results    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
